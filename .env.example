# AI Chatbot Configuration

# Server Configuration
HOST=0.0.0.0
PORT=8000
FRONTEND_PORT=3000

# Ollama Configuration (Configurable as requested)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
# Alternative models: llama3.2:3b, llama3.1:8b, llama2:7b

# Audio Configuration
AUDIO_SAMPLE_RATE=16000
AUDIO_CHUNK_DURATION=3.0
AUDIO_FORMAT=wav

# Video Configuration
VIDEO_FPS=30
VIDEO_RESOLUTION=512
AVATAR_PATH=avatar.png

# Model Paths
WHISPER_MODEL=medium
WHISPER_DEVICE=cuda
GPT_SOVITS_MODEL_PATH=external/GPT-SoVITS
SADTALKER_MODEL_PATH=external/SadTalker

# Performance Settings (Optimized for RTX 4090)
MAX_CONCURRENT_SESSIONS=3
GPU_MEMORY_FRACTION=0.8
ENABLE_MODEL_CACHING=true
BATCH_SIZE=1

# Temporary Files
TEMP_DIR=temp
CLEANUP_TEMP_FILES=true
MAX_TEMP_FILE_AGE=3600

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/chatbot.log

# Development
DEBUG=false
RELOAD=true 